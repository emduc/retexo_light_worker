# default configuration

app: "hetero_pos_neg_train" # hetero_pos_neg_train, partition_data
retexo: true
custom_note: "none"
dataset_name: "mind"
mind_version: "small"
dataset_dir: ./datasets
partition_dir: ./datasets/partitions/
partition_method: "random"
train_sampler: "MultiLayerFull"
part_obj: "vol"
num_partitions: 1
num_layers: 2
hidden_dim: 128
feat_hidden: 128
adaptor_hidden: 256
loss_func: "cross_entropy"
num_rounds: [20, 20, 20]
early_stop: 50
layer_early_stop: [500, 500, 500]
gnn_neg_ratio: 1
gnn_kl_weight: 0
local_epochs: 1
learning_rate: [5e-4, 1e-3, 1e-3]
momentum: 0.9
weight_decay: 0.0005
eval_every: [5, 5, 5]
eval_after: [9, 9, 9]
val_size: 10
wandb_mode: "offline"
cross_score: false
dropout: 0
seed: 7
log_every: 10
print_all: false
best_model: true
node_rank: 0
parts_per_node: 4
device: "cpu"
measure_dv: false
sleep_time: 0.0
cache_size: 5
debug: true
federated: true

quick_eval: true
gnn_quick_dev_reco: true
gnn_quick_dev_reco_size: 10000

dataset:
  download:
    dataset_name: ${dataset_name}
    dataset_dir: ${dataset_dir}
    add_self_loop: false

  partition:
    dataset_name: ${dataset_name}-${partition_method}-${part_obj}-${num_partitions}
    part_method: ${partition_method}
    num_parts: ${num_partitions}
    part_obj: ${part_obj}
    partition_dir: ${partition_dir}

  batching:
    batch_size: ${batch_size}
    shuffle: true
    num_workers: 4

model:
  _target_: models.gnn.SimpleGNN
  _recursive_: false
  hidden_dim: ${hidden_dim}
  n_layers: ${num_layers}
  dropout: ${dropout}
  conv_layer:
    _target_: models.sage.CustomSAGEConv
    aggregator_type: "mean"

optimizer:
  _target_: torch.optim.Adam
  weight_decay: ${weight_decay}

distributed:
  backend: "gloo"
  init_method: "tcp://"
  master_addr: 127.0.0.1
  master_port: "10100"

task:
  _target_: tasks.node_classification.NodeClassificationTask
